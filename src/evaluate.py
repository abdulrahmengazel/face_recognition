
import psycopg2
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from itertools import combinations
import random
from config import DB_CONFIG


# Ø¯Ø§Ù„Ø© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø¥Ù‚Ù„ÙŠØ¯ÙŠØ© (Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù€ pgvector <->)
def euclidean_distance(v1, v2):
    return np.linalg.norm(v1 - v2)


# Ø¯Ø§Ù„Ø© Ù„Ø­Ø³Ø§Ø¨ ØªØ´Ø§Ø¨Ù‡ Ø¬ÙŠØ¨ Ø§Ù„ØªÙ…Ø§Ù… (Ù…Ø·Ø§Ø¨Ù‚Ø© Ù„Ù€ pgvector <=>)
# FaceNet ÙŠÙØ¶Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø³Ø§ÙØ© Ø¹Ø§Ø¯Ø©
def cosine_distance(v1, v2):
    dot_product = np.dot(v1, v2)
    norm_v1 = np.linalg.norm(v1)
    norm_v2 = np.linalg.norm(v2)
    return 1 - (dot_product / (norm_v1 * norm_v2))


def evaluate_thresholds():
    print("ğŸ”„ Connecting to Database and fetching embeddings...")

    # ... Ø¯Ø§Ø®Ù„ Ø¯Ø§Ù„Ø© evaluate_thresholds ...

    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()

    # --- Ø§Ù„ØªØµØ­ÙŠØ­: Ø§Ø³ØªØ®Ø¯Ø§Ù… JOIN Ù„Ø¬Ù„Ø¨ Ø§Ù„Ø§Ø³Ù… Ù…Ù† Ø¬Ø¯ÙˆÙ„ people ÙˆØ§Ù„Ø¨ØµÙ…Ø© Ù…Ù† face_encodings ---
    query = """
            SELECT p.name, f.encoding_facenet
            FROM face_encodings f
                     JOIN people p ON f.person_id = p.id
            WHERE f.encoding_facenet IS NOT NULL; \
            """

    cur.execute(query)
    rows = cur.fetchall()
    conn.close()

    # ... Ø¨Ø§Ù‚ÙŠ Ø§Ù„ÙƒÙˆØ¯ ÙƒÙ…Ø§ Ù‡Ùˆ ...

    if not rows:
        print("âŒ No data found in database!")
        return

    print(f"âœ… Loaded {len(rows)} face embeddings. Processing pairs...")

    # ØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: { "George_Bush": [vec1, vec2, ...], ... }
    people_data = {}
    for name, encoding in rows:
        # --- Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„ØªØ¹Ø¯ÙŠÙ„: Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Øµ Ø§Ù„Ù‚Ø§Ø¯Ù… Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
        if isinstance(encoding, str):
            # 1. Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ù‚ÙˆØ§Ø³ Ø§Ù„Ù…Ø±Ø¨Ø¹Ø© [ ]
            cleaned_str = encoding.replace('[', '').replace(']', '')
            # 2. ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø£Ø±Ù‚Ø§Ù… (Floats)
            encoding = [float(x) for x in cleaned_str.split(',') if x.strip()]
        # --- Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ ---

        # Ø§Ù„Ø¢Ù† Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù„Ù€ Numpy Ø³ÙŠØªÙ… Ø¨Ù†Ø¬Ø§Ø­
        vec = np.array(encoding, dtype=np.float32)

        if name not in people_data:
            people_data[name] = []
        people_data[name].append(vec)

    positive_distances = []  # Ù†ÙØ³ Ø§Ù„Ø´Ø®Øµ
    negative_distances = []  # Ø£Ø´Ø®Ø§Øµ Ù…Ø®ØªÙ„ÙÙŠÙ†

    names_list = list(people_data.keys())

    # 1. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ù„Ù†ÙØ³ Ø§Ù„Ø´Ø®Øµ (Positives)
    for name, vecs in people_data.items():
        if len(vecs) > 1:
            # Ø¥Ù†Ø´Ø§Ø¡ ÙƒÙ„ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø§Ù„Ù…Ù…ÙƒÙ†Ø© Ø¨ÙŠÙ† ØµÙˆØ± Ù†ÙØ³ Ø§Ù„Ø´Ø®Øµ
            for v1, v2 in combinations(vecs, 2):
                dist = euclidean_distance(v1, v2)  # ØºÙŠÙ‘Ø± Ø¥Ù„Ù‰ cosine_distance Ù„Ùˆ Ø£Ø±Ø¯Øª
                positive_distances.append(dist)

    # 2. Ø­Ø³Ø§Ø¨ Ù…Ø³Ø§ÙØ§Øª Ù„Ø£Ø´Ø®Ø§Øµ Ù…Ø®ØªÙ„ÙÙŠÙ† (Negatives)
    # Ù†Ø£Ø®Ø° Ø¹ÙŠÙ†Ø© Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ù„ØªÙˆÙÙŠØ± Ø§Ù„ÙˆÙ‚Øª (Ù…Ø«Ù„Ø§Ù‹ 10,000 Ø²ÙˆØ¬)
    num_negatives = min(len(positive_distances) * 2, 20000)
    if num_negatives == 0: num_negatives = 1000

    print(f"ğŸ“Š Calculating {len(positive_distances)} positive pairs and ~{num_negatives} negative pairs...")

    for _ in range(num_negatives):
        name1, name2 = random.sample(names_list, 2)
        # ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø§Ø³Ù…ÙŠÙ† Ù…Ø®ØªÙ„ÙÙŠÙ†
        while name1 == name2:
            name1, name2 = random.sample(names_list, 2)

        vec1 = random.choice(people_data[name1])
        vec2 = random.choice(people_data[name2])

        dist = euclidean_distance(vec1, vec2)
        negative_distances.append(dist)

    # --- Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ ---
    plt.figure(figsize=(12, 6))

    # Ø±Ø³Ù… ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ù„Ù†ÙØ³ Ø§Ù„Ø´Ø®Øµ (Ø£Ø®Ø¶Ø±)
    sns.kdeplot(positive_distances, fill=True, color='green', label='Same Person (Match)')

    # Ø±Ø³Ù… ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ù„Ø£Ø´Ø®Ø§Øµ Ù…Ø®ØªÙ„ÙÙŠÙ† (Ø£Ø­Ù…Ø±)
    sns.kdeplot(negative_distances, fill=True, color='red', label='Different People (No Match)')

    plt.title('FaceNet Distance Distribution (LFW Data)')
    plt.xlabel('Distance (Euclidean)')
    plt.ylabel('Density')
    plt.legend()
    plt.grid(True, alpha=0.3)

    # Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ù…
    plt.savefig("threshold_analysis.png")
    print("ğŸ“ˆ Graph saved as 'threshold_analysis.png'. Check it to pick your threshold!")
    plt.show()

    # --- Ø§Ù‚ØªØ±Ø§Ø­ Ø£ÙØ¶Ù„ Threshold ---
    # Ù‡Ùˆ Ø§Ù„Ø±Ù‚Ù… Ø§Ù„Ø°ÙŠ ÙŠÙØµÙ„ Ø¨ÙŠÙ† Ø§Ù„ØªÙˆØ²ÙŠØ¹ÙŠÙ† Ø¨Ø£Ù‚Ù„ Ø®Ø·Ø£
    suggested_threshold = 0
    min_overlap = float('inf')

    # ÙØ­Øµ Ù†Ø·Ø§Ù‚ Ù…Ø³Ø§ÙØ§Øª ØªØ¬Ø±ÙŠØ¨ÙŠ
    for t in np.arange(0, 2.0, 0.01):
        # False Negatives: Ø£Ø´Ø®Ø§Øµ Ù†ÙØ³ Ø¨Ø¹Ø¶ØŒ Ù„ÙƒÙ† Ù…Ø³Ø§ÙØªÙ‡Ù… Ø£ÙƒØ¨Ø± Ù…Ù† Ø§Ù„Ø¹ØªØ¨Ø©
        fn = sum(1 for d in positive_distances if d > t)
        # False Positives: Ø£Ø´Ø®Ø§Øµ Ù…Ø®ØªÙ„ÙÙŠÙ†ØŒ Ù„ÙƒÙ† Ù…Ø³Ø§ÙØªÙ‡Ù… Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ø¹ØªØ¨Ø©
        fp = sum(1 for d in negative_distances if d < t)

        total_errors = fn + fp
        if total_errors < min_overlap:
            min_overlap = total_errors
            suggested_threshold = t

    print(f"\nğŸ† Suggested Optimal Threshold: {suggested_threshold:.2f}")
    print(f"   (Use this value in your config.py)")


if __name__ == "__main__":
    evaluate_thresholds()